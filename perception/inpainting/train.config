[optimizer]
optimizer = adam
learning_rate = 0.001
momentum = 0.9
betas = 0.9, 0.999
epsilon = 1e-8
weight_decay = 0

[training]
loss = mse
batch_size_train = 128
batch_size_test = 128
epochs = 100